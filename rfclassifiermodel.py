# -*- coding: utf-8 -*-
"""RFClassifiermodel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LYsf31aMwceQqW7Tv31Y1KOphejTzmA-
"""

# Importing necessary libraries
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
import joblib
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

# Load your dataset
data = pd.read_csv("Netflix Userbase.csv")
print(data.head())
print(data.info())

# Find the maximum date in the 'Join Date' and 'Last Payment Date' columns
max_join_date = data['Join Date'].max()
max_payment_date = data['Last Payment Date'].max()

# Determine the end date in the dataset
end_date = max(max_join_date, max_payment_date)

# Display the end date
print("End date of the dataset:", end_date)

# Convert 'Join Date' and 'Last Payment Date' to datetime objects
data['Join Date'] = pd.to_datetime(data['Join Date'], format='%d/%m/%Y', errors='coerce')
data['Last Payment Date'] = pd.to_datetime(data['Last Payment Date'], format='%d/%m/%Y', errors='coerce')

# Calculate the number of days between 'Join Date' and 'Last Payment Date'
data['Days Active'] = (data['Last Payment Date'] - data['Join Date']).dt.days

# Create a binary churn column: 1 if churned, 0 if not
data['Churn'] = (data['Days Active'] < 355).astype(int)

# Display the first few rows to check the new churn column
print(data.head())

# Count the number of churns (0 and 1)
churn_counts = data['Churn'].value_counts()
print("\nChurn Counts (0 and 1):")
print(churn_counts)

# Convert the 'Join Date' and 'Last Payment Date' columns to datetime objects
data['Join Date'] = pd.to_datetime(data['Join Date'], format='%d-%m-%y', errors='coerce')
data['Last Payment Date'] = pd.to_datetime(data['Last Payment Date'], format='%d-%m-%y', errors='coerce')

# Find the earliest and latest dates for 'Join Date'
earliest_join_date = data['Join Date'].min()
latest_join_date = data['Join Date'].max()

# Find the earliest and latest dates for 'Last Payment Date'
earliest_last_payment_date = data['Last Payment Date'].min()
latest_last_payment_date = data['Last Payment Date'].max()

# Determine the overall time range covered in the dataset
overall_earliest_date = min(earliest_join_date, earliest_last_payment_date)
overall_latest_date = max(latest_join_date, latest_last_payment_date)

# Calculate the time span in years
time_span_years = (overall_latest_date - overall_earliest_date).days / 365.25

# Print the results
print(f"Earliest Join Date: {earliest_join_date}")
print(f"Latest Join Date: {latest_join_date}")
print(f"Earliest Last Payment Date: {earliest_last_payment_date}")
print(f"Latest Last Payment Date: {latest_last_payment_date}")
print(f"Overall Time Range: {overall_earliest_date} to {overall_latest_date}")
print(f"Time Span in Years: {time_span_years:.2f}")

# Check for any issues in conversion
print("Sample data preview:")
print(data.head())
print("\nData info:")
print(data.info())

# Prepare features and target variable
features = ['Subscription Type', 'Age', 'Monthly Revenue', 'Device']
X = pd.get_dummies(data[features])  # Convert categorical features to dummy variables
y = data['Churn']

# Check class distribution to identify imbalance
print("Class distribution in target variable:\n", y.value_counts())

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Initialize the RandomForestClassifier with simplified parameters and class weighting
rf_simplified = RandomForestClassifier(
    n_estimators=50,         # Fewer trees
    max_depth=10,            # Limited depth
    min_samples_split=5,
    min_samples_leaf=2,
    class_weight='balanced', # Handle class imbalance
    random_state=42
)

# Fit the simplified model with the training data
rf_simplified.fit(X_train, y_train)

# Predict on the validation set
y_val_pred = rf_simplified.predict(X_val)

# Evaluate the simplified model on the validation set
print("Validation Accuracy (Simplified Model):", accuracy_score(y_val, y_val_pred))
print("Validation Classification Report (Simplified Model):\n", classification_report(y_val, y_val_pred))

# Predict on the test set using the simplified model
y_pred = rf_simplified.predict(X_test)

# Evaluate the simplified model on the test set
print("Test Accuracy (Simplified Model):", accuracy_score(y_test, y_pred))
print("Test Classification Report (Simplified Model):\n", classification_report(y_test, y_pred))

# Plot the confusion matrix for the test set
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
print("Confusion Matrix (Simplified Model):\n", cm)

# Check for feature importance
feature_importances = pd.Series(rf_simplified.feature_importances_, index=X.columns)
print("Feature Importances (Simplified Model):\n", feature_importances.sort_values(ascending=False))

# Additional diagnostics
# Check if the model overfits
train_accuracy = rf_simplified.score(X_train, y_train)
test_accuracy = rf_simplified.score(X_test, y_test)
print(f"Training Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize the RandomForestClassifier with class weights
rf = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=5, min_samples_leaf=5, class_weight='balanced', random_state=42)

# Fit the model with the training data
rf.fit(X_train, y_train)

# Predict on the test set
y_pred = rf.predict(X_test)

# Evaluate the model on the test set
print("Test Accuracy:", accuracy_score(y_test, y_pred))
print("Test Classification Report:\n", classification_report(y_test, y_pred))

# Plot the confusion matrix for the test set
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
print("Confusion Matrix:\n", cm)

# Check feature importances
feature_importances = pd.Series(rf.feature_importances_, index=X.columns)
print("Feature Importances:\n", feature_importances.sort_values(ascending=False))

from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score

# Splitting the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Applying SMOTE
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Training the model
model = RandomForestClassifier(random_state=42)
model.fit(X_train_resampled, y_train_resampled)

# Predicting
y_pred = model.predict(X_test)

# Evaluation
print("Test Accuracy:", accuracy_score(y_test, y_pred))
print("Test Classification Report:\n", classification_report(y_test, y_pred))

# Define the path to save the model
file_path = r'C:\Users\Clyde\Documents\my_streamlit_app\RFClassifier.pkl'

# Save the model to the specified path
joblib.dump(rf_simplified, file_path)
print(f"Model saved successfully at {file_path}")
